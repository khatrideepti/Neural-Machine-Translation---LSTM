{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Machine Translation\n",
    "\n",
    "## Introduction\n",
    "In this notebook, we will build a deep neural network that functions as part of an end-to-end machine translation pipeline. The completed pipeline will accept french text as input and return the english translation.\n",
    "\n",
    "__Proposed Approach__\n",
    "\n",
    "- Preprocessing: Load and examine data, cleaning, tokenization, padding\n",
    "- Modeling: Build an encoder-decoder model with Attention\n",
    "- Prediction: Generate specific translations of French to English, and compare the output translations to the ground truth translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "from builtins import range, input\n",
    "import pickle\n",
    "import os, sys\n",
    "import string\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Embedding, \\\n",
    "  Bidirectional, RepeatVector, Concatenate, Activation, Dot, Lambda\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras.backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import adam\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "% matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 100\n",
    "LATENT_DIM = 256\n",
    "LATENT_DIM_DECODER = 256 \n",
    "EMBEDDING_DIM = 200\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "We begin by investigating the dataset that will be used to train and evaluate your pipeline.  \n",
    "\n",
    "### Load Data - Train and Test \n",
    "The `data_en` file contains English sentences with their French translations in the `data_fr` file. Load the English and French data from these files from running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('French_test.pkl', 'rb') as handle:\n",
    "    fr_test = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('English_test.pkl', 'rb') as handle:\n",
    "    en_test = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('French_train.pkl', 'rb') as handle:\n",
    "    fr_train = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('English_train.pkl', 'rb') as handle:\n",
    "    en_train = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES=len(fr_test)+len(fr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample train size: 56000\n"
     ]
    }
   ],
   "source": [
    "input_texts = [] # French sentences\n",
    "target_texts = [] # English sentences\n",
    "target_texts_inputs = []# english sentences offset by 1 for teacher forcing\n",
    "\n",
    "#Converting to lowercase\n",
    "fr_train=[line.lower() for line in fr_train]\n",
    "en_train=[line.lower() for line in en_train]\n",
    "NUM_SAMPLES=len(fr_train)\n",
    "print(\"Sample train size:\",NUM_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From looking at the sentences, you can see that they have been preprocessed already.  The puncuations have been delimited using spaces. All the text have been converted to lowercase.  This should save you some time, but the text requires more preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess\n",
    "For this project, you won't use text data as input to your model. Instead, you'll convert the text into sequences of integers using the following preprocess methods:\n",
    "1. Add start and end tokens to the sentences\n",
    "2. Tokenize the words of the sentences\n",
    "3. Add padding to make all the sequences of same length.\n",
    "\n",
    "Time to start preprocessing the data...\n",
    "### Tokenize \n",
    "For a neural network to predict on text data, it first has to be turned into data it can understand. Text data like \"dog\" is a sequence of ASCII character encodings.  Since a neural network is a series of multiplication and addition operations, the input data needs to be number(s).\n",
    "\n",
    "We can turn each character into a number or each word into a number.  These are called character and word ids, respectively.  Character ids are used for character level models that generate text predictions for each character.  A word level model uses word ids that generate text predictions for each word.  Word level models tend to learn better, since they are lower in complexity, so we'll use those.\n",
    "\n",
    "Turn each sentence into a sequence of words ids using Keras's [`Tokenizer`](https://keras.io/preprocessing/text/#tokenizer) function. Use this function to tokenize `english_sentences` and `french_sentences` in the cell below.\n",
    "\n",
    "\n",
    "### Padding\n",
    "When batching the sequence of word ids together, each sequence needs to be the same length. Since sentences are dynamic in length, we can add padding to the end of the sequences to make them the same length.\n",
    "\n",
    "Make sure all the English sequences have the same length and all the French sequences have the same length by adding padding to the end of each sequence using Keras's [`pad_sequences`](https://keras.io/preprocessing/sequence/#pad_sequences) function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Preprocess Train Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding <sos> and <eos> tokens\n",
    "\n",
    "for lines in en_train:\n",
    "    target_texts_inputs.append('<sos>'+\" \"+ lines)\n",
    "    \n",
    "for lines in en_train:\n",
    "    target_texts.append(lines+ \" \" +'<eos>')\n",
    "    \n",
    "for lines in fr_train:\n",
    "    input_texts.append(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocessed\n",
      "Max train English sentence length: 9\n",
      "Max train French sentence length: 9\n",
      "Unique French Vocabulary count: 14143\n",
      "Unique English Vocabulary count: 6842\n"
     ]
    }
   ],
   "source": [
    "# tokenize French sentences\n",
    "tokenizer_inputs = Tokenizer()\n",
    "tokenizer_inputs.fit_on_texts(input_texts)\n",
    "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)\n",
    "\n",
    "# word to index mapping for French\n",
    "word2idx_inputs = tokenizer_inputs.word_index\n",
    "\n",
    "# Max length of French sentence\n",
    "max_len_input = max(len(s) for s in input_sequences)\n",
    "\n",
    "#tokenize English sentences\n",
    "tokenizer_outputs = Tokenizer(filters='')\n",
    "tokenizer_outputs.fit_on_texts(target_texts + target_texts_inputs) \n",
    "target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\n",
    "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_texts_inputs)\n",
    "\n",
    "# Word to index mapping for English\n",
    "word2idx_outputs = tokenizer_outputs.word_index\n",
    "\n",
    "# store number of output words for later\n",
    "num_words_output = len(word2idx_outputs) + 1\n",
    "\n",
    "# Max length of English sentence\n",
    "max_len_target = max(len(s) for s in target_sequences)\n",
    "\n",
    "# pad the sequences\n",
    "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n",
    "decoder_inputs = pad_sequences(target_sequences_inputs, maxlen=max_len_target, padding='post')\n",
    "decoder_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding='post')\n",
    "\n",
    "print('Data Preprocessed')\n",
    "print(\"Max train English sentence length:\", max_len_target)\n",
    "print(\"Max train French sentence length:\", max_len_input)\n",
    "print(\"Unique French Vocabulary count:\",len(word2idx_inputs))\n",
    "print(\"Unique English Vocabulary count:\",len(word2idx_outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Preprocess Test Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test Preparation\n",
    "input_texts_test = [] # French sentences\n",
    "target_texts_test = [] # English sentences\n",
    "target_texts_inputs_test = []# english sentences offset by 1 for teacher forcing\n",
    "\n",
    "#Converting to lowercase\n",
    "fr_test=[line.lower() for line in fr_test]\n",
    "en_test=[line.lower() for line in en_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding <sos> and <eos> tokens\n",
    "\n",
    "for lines in en_test:\n",
    "    target_texts_inputs_test.append('<sos>'+\" \"+ lines)\n",
    "    \n",
    "for lines in en_test:\n",
    "    target_texts_test.append(lines+ \" \" +'<eos>')\n",
    "    \n",
    "for lines in fr_test:\n",
    "    input_texts_test.append(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max test English sentence length: 9\n",
      "Max test French sentence length: 9\n"
     ]
    }
   ],
   "source": [
    "# tokenize French sentences\n",
    "\n",
    "input_sequences_test = tokenizer_inputs.texts_to_sequences(input_texts_test)\n",
    "\n",
    "\n",
    "target_sequences_test = tokenizer_outputs.texts_to_sequences(target_texts_test)\n",
    "target_sequences_inputs_test = tokenizer_outputs.texts_to_sequences(target_texts_inputs_test)\n",
    "\n",
    "# pad the sequences\n",
    "encoder_inputs_test = pad_sequences(input_sequences_test, maxlen=max_len_input)\n",
    "decoder_inputs_test = pad_sequences(target_sequences_inputs_test, maxlen=max_len_target, padding='post')\n",
    "decoder_targets_test = pad_sequences(target_sequences_test, maxlen=max_len_target, padding='post')\n",
    "\n",
    "print(\"Max test English sentence length:\", decoder_inputs_test.shape[1])\n",
    "print(\"Max test French sentence length:\", encoder_inputs_test.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding\n",
    "\n",
    "In word embeddings, every word is represented as an n-dimensional dense vector. The words that are similar will have similar vector. The position of a word within the vector space is learned from text and is based on the words that surround the word when it is used.\n",
    "\n",
    "For French sentences, i.e. the inputs, we will use the [`GloVe`](https://nlp.stanford.edu/projects/glove/) word embeddings. For the translated English sentences in the output, we will use custom word embeddings.\n",
    "\n",
    "Let's create word embeddings for the inputs first. To do so, we need to load the GloVe word vectors into memory. We will then create a dictionary where words are the keys and the corresponding vectors are values, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "#Load pretrained word vectors from Glove\n",
    "print('Loading word vectors...')\n",
    "word2vec = {}\n",
    "with open(os.path.join('glove.6B/glove.6B.%sd.txt' % EMBEDDING_DIM), encoding=\"utf8\") as f:\n",
    "  # is just a space-separated text file in the format:\n",
    "  # word vec[0] vec[1] vec[2] ...\n",
    "  for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vec = np.asarray(values[1:], dtype='float32')\n",
    "    word2vec[word] = vec\n",
    "print('Found %s word vectors.' % len(word2vec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling pre-trained embeddings...\n"
     ]
    }
   ],
   "source": [
    "# prepare embedding matrix\n",
    "print('Filling pre-trained embeddings...')\n",
    "num_words=len(word2idx_inputs) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word2idx_inputs.items():\n",
    "  if i < num_words:\n",
    "    embedding_vector = word2vec.get(word)\n",
    "    if embedding_vector is not None:\n",
    "      # words not found in embedding index will be all zeros.\n",
    "      embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Model\n",
    "The idea is to have two recurrent neural networks (RNNs) with an encoder-decoder architecture: read the input words one by one to obtain a vector representation of a fixed dimensionality (encoder), and, conditioned on these inputs, extract the output words one by one using another RNN (decoder).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Softmax Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_over_time(x):\n",
    "  assert(K.ndim(x) > 2)\n",
    "  e = K.exp(x - K.max(x, axis=1, keepdims=True))\n",
    "  s = K.sum(e, axis=1, keepdims=True)\n",
    "  return e / s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embedding layer\n",
    "embedding_layer = Embedding(\n",
    "  num_words,\n",
    "  EMBEDDING_DIM,\n",
    "  weights=[embedding_matrix],\n",
    "  input_length=max_len_input,\n",
    "  # trainable=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot Encoding\n",
    "\n",
    "To make predictions, the final layer of the model will be a dense layer, therefore we need the outputs in the form of one-hot encoded vectors, since we will be using softmax activation function at the dense layer. To create such one-hot encoded output, the next step is to assign 1 to the column number that corresponds to the integer representation of the word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "decoder_targets_one_hot = np.zeros(\n",
    "  (\n",
    "    len(input_texts),\n",
    "    max_len_target,\n",
    "    num_words_output\n",
    "  ),\n",
    "  dtype='float32'\n",
    ")\n",
    "\n",
    "# assign the values\n",
    "for i, d in enumerate(decoder_targets):\n",
    "  for t, word in enumerate(d):\n",
    "    decoder_targets_one_hot[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Encoding Layer\n",
    "The input to the encoder will be the sentence in French and the output will be the hidden state and cell state of the LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder\n",
    "encoder_inputs_placeholder = Input(shape=(max_len_input,))\n",
    "x = embedding_layer(encoder_inputs_placeholder)\n",
    "encoder = Bidirectional(LSTM(\n",
    "  LATENT_DIM,\n",
    "  return_sequences=True, dropout=0.2\n",
    "))\n",
    "encoder_outputs = encoder(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Decoder Layer\n",
    "\n",
    "The next step is to define the decoder. The decoder will have two inputs: the hidden state and cell state from the encoder and the input sentence, which actually will be the output sentence with an \"</sos/>\" token appended at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoder\n",
    "decoder_inputs_placeholder = Input(shape=(max_len_target,))\n",
    "decoder_embedding = Embedding(num_words_output, EMBEDDING_DIM)\n",
    "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Attention Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the performance of the Neural Machine Translator, Attention mechanism (Dot attention) is implemented. The attention model develops a context vector that is filtered specifically for each output time step.\n",
    "\n",
    "Attention places different focus on different words by assigning each word with a score. Then, using the softmaxed scores, we aggregate the encoder hidden states using a weighted sum of the encoder hidden states, to get the context vector. \n",
    "\n",
    "Rather than re-iterating through the equations for calculating attention, a function `one_step_attention` is defined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attention\n",
    "attn_repeat_layer = RepeatVector(max_len_input)\n",
    "attn_concat_layer = Concatenate(axis=-1)\n",
    "attn_dense1 = Dense(10, activation='tanh')\n",
    "attn_dense2 = Dense(1, activation=softmax_over_time)\n",
    "\n",
    "attn_dot = Dot(axes=1) # to perform the weighted sum of alpha[t] * h[t]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_attention(h, st_1):\n",
    "  # h = h(1), ..., h(Tx), shape = (Tx, LATENT_DIM * 2)\n",
    "  # st_1 = s(t-1), shape = (LATENT_DIM_DECODER,)\n",
    " \n",
    "  # copy s(t-1) Tx times\n",
    "  # now shape = (Tx, LATENT_DIM_DECODER)\n",
    "  st_1 = attn_repeat_layer(st_1)\n",
    "\n",
    "  # Concatenate all h(t)'s with s(t-1)\n",
    "  # Now of shape (Tx, LATENT_DIM_DECODER + LATENT_DIM * 2)\n",
    "  x = attn_concat_layer([h, st_1])\n",
    "\n",
    "  # Neural net first layer\n",
    "  x = attn_dense1(x)\n",
    "\n",
    "  # Neural net second layer with special softmax over time\n",
    "  alphas = attn_dense2(x)\n",
    "\n",
    "  # \"Dot\" the alphas and the h's\n",
    "  # Remember a.dot(b) = sum over a[t] * b[t]\n",
    "  context = attn_dot([alphas, h])\n",
    "\n",
    "  return context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the rest of the decoder (after attention)\n",
    "decoder_lstm = LSTM(LATENT_DIM_DECODER, return_state=True)\n",
    "decoder_dense = Dense(num_words_output, activation='softmax')\n",
    "\n",
    "initial_s = Input(shape=(LATENT_DIM_DECODER,), name='s0')\n",
    "initial_c = Input(shape=(LATENT_DIM_DECODER,), name='c0')\n",
    "context_last_word_concat_layer = Concatenate(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s, c will be re-assigned in each iteration of the loop\n",
    "s = initial_s\n",
    "c = initial_c\n",
    "\n",
    "# collect outputs in a list at first\n",
    "outputs = []\n",
    "for t in range(max_len_target): # Ty times\n",
    "  # get the context using attention\n",
    "  context = one_step_attention(encoder_outputs, s)\n",
    "\n",
    "  # we need a different layer for each time step\n",
    "  selector = Lambda(lambda x: x[:, t:t+1])\n",
    "  xt = selector(decoder_inputs_x)\n",
    "  \n",
    "  # combine \n",
    "  decoder_lstm_input = context_last_word_concat_layer([context, xt])\n",
    "\n",
    "  # pass the combined [context, last word] into the LSTM\n",
    "  # along with [s, c]\n",
    "  # get the new [s, c] and output\n",
    "  o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[s, c])\n",
    "\n",
    "  # final dense layer to get next word prediction\n",
    "  decoder_outputs = decoder_dense(o)\n",
    "  outputs.append(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_and_transpose(x):\n",
    "  # x is a list of length T, each element is a batch_size x output_vocab_size tensor\n",
    "  x = K.stack(x) # is now T x batch_size x output_vocab_size tensor\n",
    "  x = K.permute_dimensions(x, pattern=(1, 0, 2)) # is now batch_size x T x output_vocab_size\n",
    "  return x\n",
    "\n",
    "# make it a layerx``\n",
    "stacker = Lambda(stack_and_transpose)\n",
    "outputs = stacker(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "model = Model(\n",
    "  inputs=[\n",
    "    encoder_inputs_placeholder,\n",
    "    decoder_inputs_placeholder,\n",
    "    initial_s, \n",
    "    initial_c,\n",
    "  ],\n",
    "  outputs=outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.001\n",
    "# checkpoint\n",
    "filepath=\"french_eng_finalmodel\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# compile the model\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate) ,loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sinch\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\sinch\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 44800 samples, validate on 11200 samples\n",
      "Epoch 1/100\n",
      "44800/44800 [==============================] - 219s 5ms/step - loss: 4.2594 - accuracy: 0.4159 - val_loss: 3.5345 - val_accuracy: 0.4184\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.41835, saving model to french_eng_finalmodel\n",
      "Epoch 2/100\n",
      "44800/44800 [==============================] - 218s 5ms/step - loss: 3.3653 - accuracy: 0.4250 - val_loss: 3.2593 - val_accuracy: 0.4609\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.41835 to 0.46089, saving model to french_eng_finalmodel\n",
      "Epoch 3/100\n",
      "44800/44800 [==============================] - 220s 5ms/step - loss: 3.1405 - accuracy: 0.5379 - val_loss: 3.0870 - val_accuracy: 0.5537\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.46089 to 0.55372, saving model to french_eng_finalmodel\n",
      "Epoch 4/100\n",
      "44800/44800 [==============================] - 214s 5ms/step - loss: 3.0053 - accuracy: 0.5571 - val_loss: 2.9825 - val_accuracy: 0.5557\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.55372 to 0.55572, saving model to french_eng_finalmodel\n",
      "Epoch 5/100\n",
      "44800/44800 [==============================] - 212s 5ms/step - loss: 2.9146 - accuracy: 0.5610 - val_loss: 2.9113 - val_accuracy: 0.5635\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.55572 to 0.56351, saving model to french_eng_finalmodel\n",
      "Epoch 6/100\n",
      "44800/44800 [==============================] - 212s 5ms/step - loss: 2.8501 - accuracy: 0.5656 - val_loss: 2.8583 - val_accuracy: 0.5678\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.56351 to 0.56782, saving model to french_eng_finalmodel\n",
      "Epoch 7/100\n",
      "44800/44800 [==============================] - 225s 5ms/step - loss: 2.8006 - accuracy: 0.5704 - val_loss: 2.8177 - val_accuracy: 0.5706\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.56782 to 0.57056, saving model to french_eng_finalmodel\n",
      "Epoch 8/100\n",
      "44800/44800 [==============================] - 233s 5ms/step - loss: 2.7585 - accuracy: 0.5732 - val_loss: 2.7809 - val_accuracy: 0.5712\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.57056 to 0.57120, saving model to french_eng_finalmodel\n",
      "Epoch 9/100\n",
      "44800/44800 [==============================] - 232s 5ms/step - loss: 2.7217 - accuracy: 0.5745 - val_loss: 2.7482 - val_accuracy: 0.5725\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.57120 to 0.57251, saving model to french_eng_finalmodel\n",
      "Epoch 10/100\n",
      "44800/44800 [==============================] - 232s 5ms/step - loss: 2.6857 - accuracy: 0.5772 - val_loss: 2.7204 - val_accuracy: 0.5763\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.57251 to 0.57633, saving model to french_eng_finalmodel\n",
      "Epoch 11/100\n",
      "44800/44800 [==============================] - 240s 5ms/step - loss: 2.6481 - accuracy: 0.5817 - val_loss: 2.6849 - val_accuracy: 0.5785\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.57633 to 0.57854, saving model to french_eng_finalmodel\n",
      "Epoch 12/100\n",
      "44800/44800 [==============================] - 243s 5ms/step - loss: 2.6152 - accuracy: 0.5839 - val_loss: 2.6509 - val_accuracy: 0.5815\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.57854 to 0.58147, saving model to french_eng_finalmodel\n",
      "Epoch 13/100\n",
      "44800/44800 [==============================] - 230s 5ms/step - loss: 2.5777 - accuracy: 0.5867 - val_loss: 2.6258 - val_accuracy: 0.5828\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.58147 to 0.58278, saving model to french_eng_finalmodel\n",
      "Epoch 14/100\n",
      "44800/44800 [==============================] - 230s 5ms/step - loss: 2.5461 - accuracy: 0.5890 - val_loss: 2.5926 - val_accuracy: 0.5858\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.58278 to 0.58576, saving model to french_eng_finalmodel\n",
      "Epoch 15/100\n",
      "44800/44800 [==============================] - 220s 5ms/step - loss: 2.5149 - accuracy: 0.5923 - val_loss: 2.5688 - val_accuracy: 0.5902\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.58576 to 0.59016, saving model to french_eng_finalmodel\n",
      "Epoch 16/100\n",
      "44800/44800 [==============================] - 227s 5ms/step - loss: 2.4816 - accuracy: 0.5965 - val_loss: 2.5269 - val_accuracy: 0.5933\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.59016 to 0.59331, saving model to french_eng_finalmodel\n",
      "Epoch 17/100\n",
      "44800/44800 [==============================] - 237s 5ms/step - loss: 2.4350 - accuracy: 0.6015 - val_loss: 2.4849 - val_accuracy: 0.5983\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.59331 to 0.59832, saving model to french_eng_finalmodel\n",
      "Epoch 18/100\n",
      "44800/44800 [==============================] - 234s 5ms/step - loss: 2.3933 - accuracy: 0.6051 - val_loss: 2.4504 - val_accuracy: 0.6011\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.59832 to 0.60113, saving model to french_eng_finalmodel\n",
      "Epoch 19/100\n",
      "44800/44800 [==============================] - 239s 5ms/step - loss: 2.3474 - accuracy: 0.6091 - val_loss: 2.4013 - val_accuracy: 0.6060\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.60113 to 0.60601, saving model to french_eng_finalmodel\n",
      "Epoch 20/100\n",
      "44800/44800 [==============================] - 229s 5ms/step - loss: 2.2965 - accuracy: 0.6140 - val_loss: 2.3487 - val_accuracy: 0.6117\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.60601 to 0.61169, saving model to french_eng_finalmodel\n",
      "Epoch 21/100\n",
      "44800/44800 [==============================] - 236s 5ms/step - loss: 2.2346 - accuracy: 0.6228 - val_loss: 2.2893 - val_accuracy: 0.6211\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.61169 to 0.62113, saving model to french_eng_finalmodel\n",
      "Epoch 22/100\n",
      "44800/44800 [==============================] - 230s 5ms/step - loss: 2.1685 - accuracy: 0.6319 - val_loss: 2.2248 - val_accuracy: 0.6291\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.62113 to 0.62910, saving model to french_eng_finalmodel\n",
      "Epoch 23/100\n",
      "44800/44800 [==============================] - 224s 5ms/step - loss: 2.0980 - accuracy: 0.6409 - val_loss: 2.1594 - val_accuracy: 0.6392\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.62910 to 0.63919, saving model to french_eng_finalmodel\n",
      "Epoch 24/100\n",
      "44800/44800 [==============================] - 226s 5ms/step - loss: 2.0246 - accuracy: 0.6524 - val_loss: 2.0860 - val_accuracy: 0.6514\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.63919 to 0.65145, saving model to french_eng_finalmodel\n",
      "Epoch 25/100\n",
      "44800/44800 [==============================] - 245s 5ms/step - loss: 1.9412 - accuracy: 0.6654 - val_loss: 2.0091 - val_accuracy: 0.6636\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.65145 to 0.66364, saving model to french_eng_finalmodel\n",
      "Epoch 26/100\n",
      "44800/44800 [==============================] - 237s 5ms/step - loss: 1.8561 - accuracy: 0.6769 - val_loss: 1.9303 - val_accuracy: 0.6732\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.66364 to 0.67323, saving model to french_eng_finalmodel\n",
      "Epoch 27/100\n",
      "44800/44800 [==============================] - 234s 5ms/step - loss: 1.7725 - accuracy: 0.6875 - val_loss: 1.8694 - val_accuracy: 0.6829\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.67323 to 0.68290, saving model to french_eng_finalmodel\n",
      "Epoch 28/100\n",
      "44800/44800 [==============================] - 236s 5ms/step - loss: 1.6968 - accuracy: 0.6980 - val_loss: 1.8014 - val_accuracy: 0.6924\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.68290 to 0.69239, saving model to french_eng_finalmodel\n",
      "Epoch 29/100\n",
      "44800/44800 [==============================] - 239s 5ms/step - loss: 1.6254 - accuracy: 0.7077 - val_loss: 1.7433 - val_accuracy: 0.7003\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.69239 to 0.70031, saving model to french_eng_finalmodel\n",
      "Epoch 30/100\n",
      "44800/44800 [==============================] - 241s 5ms/step - loss: 1.5561 - accuracy: 0.7167 - val_loss: 1.6913 - val_accuracy: 0.7069\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.70031 to 0.70690, saving model to french_eng_finalmodel\n",
      "Epoch 31/100\n",
      "44800/44800 [==============================] - 229s 5ms/step - loss: 1.4918 - accuracy: 0.7257 - val_loss: 1.6386 - val_accuracy: 0.7137\n",
      "\n",
      "Epoch 00031: val_accuracy improved from 0.70690 to 0.71372, saving model to french_eng_finalmodel\n",
      "Epoch 32/100\n",
      "44800/44800 [==============================] - 228s 5ms/step - loss: 1.4288 - accuracy: 0.7339 - val_loss: 1.5940 - val_accuracy: 0.7204\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.71372 to 0.72038, saving model to french_eng_finalmodel\n",
      "Epoch 33/100\n",
      "44800/44800 [==============================] - 240s 5ms/step - loss: 1.3682 - accuracy: 0.7427 - val_loss: 1.5488 - val_accuracy: 0.7267\n",
      "\n",
      "Epoch 00033: val_accuracy improved from 0.72038 to 0.72675, saving model to french_eng_finalmodel\n",
      "Epoch 34/100\n",
      "44800/44800 [==============================] - 223s 5ms/step - loss: 1.3098 - accuracy: 0.7516 - val_loss: 1.5073 - val_accuracy: 0.7321\n",
      "\n",
      "Epoch 00034: val_accuracy improved from 0.72675 to 0.73210, saving model to french_eng_finalmodel\n",
      "Epoch 35/100\n",
      "44800/44800 [==============================] - 223s 5ms/step - loss: 1.2528 - accuracy: 0.7601 - val_loss: 1.4646 - val_accuracy: 0.7389\n",
      "\n",
      "Epoch 00035: val_accuracy improved from 0.73210 to 0.73894, saving model to french_eng_finalmodel\n",
      "Epoch 36/100\n",
      "44800/44800 [==============================] - 218s 5ms/step - loss: 1.1985 - accuracy: 0.7679 - val_loss: 1.4273 - val_accuracy: 0.7464\n",
      "\n",
      "Epoch 00036: val_accuracy improved from 0.73894 to 0.74639, saving model to french_eng_finalmodel\n",
      "Epoch 37/100\n",
      "44800/44800 [==============================] - 213s 5ms/step - loss: 1.1438 - accuracy: 0.7767 - val_loss: 1.3908 - val_accuracy: 0.7501\n",
      "\n",
      "Epoch 00037: val_accuracy improved from 0.74639 to 0.75011, saving model to french_eng_finalmodel\n",
      "Epoch 38/100\n",
      "44800/44800 [==============================] - 219s 5ms/step - loss: 1.0924 - accuracy: 0.7844 - val_loss: 1.3586 - val_accuracy: 0.7560\n",
      "\n",
      "Epoch 00038: val_accuracy improved from 0.75011 to 0.75601, saving model to french_eng_finalmodel\n",
      "Epoch 39/100\n",
      "44800/44800 [==============================] - 216s 5ms/step - loss: 1.0427 - accuracy: 0.7922 - val_loss: 1.3199 - val_accuracy: 0.7626\n",
      "\n",
      "Epoch 00039: val_accuracy improved from 0.75601 to 0.76259, saving model to french_eng_finalmodel\n",
      "Epoch 40/100\n",
      "44800/44800 [==============================] - 220s 5ms/step - loss: 0.9939 - accuracy: 0.8004 - val_loss: 1.2885 - val_accuracy: 0.7681\n",
      "\n",
      "Epoch 00040: val_accuracy improved from 0.76259 to 0.76806, saving model to french_eng_finalmodel\n",
      "Epoch 41/100\n",
      "44800/44800 [==============================] - 221s 5ms/step - loss: 0.9471 - accuracy: 0.8079 - val_loss: 1.2597 - val_accuracy: 0.7736\n",
      "\n",
      "Epoch 00041: val_accuracy improved from 0.76806 to 0.77358, saving model to french_eng_finalmodel\n",
      "Epoch 42/100\n",
      "44800/44800 [==============================] - 212s 5ms/step - loss: 0.9011 - accuracy: 0.8162 - val_loss: 1.2294 - val_accuracy: 0.7784\n",
      "\n",
      "Epoch 00042: val_accuracy improved from 0.77358 to 0.77844, saving model to french_eng_finalmodel\n",
      "Epoch 43/100\n",
      "44800/44800 [==============================] - 232s 5ms/step - loss: 0.8569 - accuracy: 0.8240 - val_loss: 1.2029 - val_accuracy: 0.7825\n",
      "\n",
      "Epoch 00043: val_accuracy improved from 0.77844 to 0.78249, saving model to french_eng_finalmodel\n",
      "Epoch 44/100\n",
      "44800/44800 [==============================] - 234s 5ms/step - loss: 0.8150 - accuracy: 0.8317 - val_loss: 1.1821 - val_accuracy: 0.7880\n",
      "\n",
      "Epoch 00044: val_accuracy improved from 0.78249 to 0.78802, saving model to french_eng_finalmodel\n",
      "Epoch 45/100\n",
      "44800/44800 [==============================] - 233s 5ms/step - loss: 0.7753 - accuracy: 0.8385 - val_loss: 1.1527 - val_accuracy: 0.7920\n",
      "\n",
      "Epoch 00045: val_accuracy improved from 0.78802 to 0.79202, saving model to french_eng_finalmodel\n",
      "Epoch 46/100\n",
      "44800/44800 [==============================] - 237s 5ms/step - loss: 0.7356 - accuracy: 0.8463 - val_loss: 1.1316 - val_accuracy: 0.7962\n",
      "\n",
      "Epoch 00046: val_accuracy improved from 0.79202 to 0.79624, saving model to french_eng_finalmodel\n",
      "Epoch 47/100\n",
      "44800/44800 [==============================] - 236s 5ms/step - loss: 0.6989 - accuracy: 0.8528 - val_loss: 1.1110 - val_accuracy: 0.8005\n",
      "\n",
      "Epoch 00047: val_accuracy improved from 0.79624 to 0.80048, saving model to french_eng_finalmodel\n",
      "Epoch 48/100\n",
      "44800/44800 [==============================] - 231s 5ms/step - loss: 0.6632 - accuracy: 0.8595 - val_loss: 1.0900 - val_accuracy: 0.8049\n",
      "\n",
      "Epoch 00048: val_accuracy improved from 0.80048 to 0.80488, saving model to french_eng_finalmodel\n",
      "Epoch 49/100\n",
      "44800/44800 [==============================] - 234s 5ms/step - loss: 0.6298 - accuracy: 0.8659 - val_loss: 1.0685 - val_accuracy: 0.8077\n",
      "\n",
      "Epoch 00049: val_accuracy improved from 0.80488 to 0.80771, saving model to french_eng_finalmodel\n",
      "Epoch 50/100\n",
      "44800/44800 [==============================] - 235s 5ms/step - loss: 0.5973 - accuracy: 0.8729 - val_loss: 1.0514 - val_accuracy: 0.8116\n",
      "\n",
      "Epoch 00050: val_accuracy improved from 0.80771 to 0.81164, saving model to french_eng_finalmodel\n",
      "Epoch 51/100\n",
      "44800/44800 [==============================] - 239s 5ms/step - loss: 0.5668 - accuracy: 0.8786 - val_loss: 1.0372 - val_accuracy: 0.8144\n",
      "\n",
      "Epoch 00051: val_accuracy improved from 0.81164 to 0.81437, saving model to french_eng_finalmodel\n",
      "Epoch 52/100\n",
      "44800/44800 [==============================] - 214s 5ms/step - loss: 0.5384 - accuracy: 0.8842 - val_loss: 1.0210 - val_accuracy: 0.8179\n",
      "\n",
      "Epoch 00052: val_accuracy improved from 0.81437 to 0.81794, saving model to french_eng_finalmodel\n",
      "Epoch 53/100\n",
      "44800/44800 [==============================] - 232s 5ms/step - loss: 0.5097 - accuracy: 0.8899 - val_loss: 1.0081 - val_accuracy: 0.8207\n",
      "\n",
      "Epoch 00053: val_accuracy improved from 0.81794 to 0.82069, saving model to french_eng_finalmodel\n",
      "Epoch 54/100\n",
      "44800/44800 [==============================] - 247s 6ms/step - loss: 0.4841 - accuracy: 0.8954 - val_loss: 0.9955 - val_accuracy: 0.8240\n",
      "\n",
      "Epoch 00054: val_accuracy improved from 0.82069 to 0.82398, saving model to french_eng_finalmodel\n",
      "Epoch 55/100\n",
      "44800/44800 [==============================] - 252s 6ms/step - loss: 0.4600 - accuracy: 0.9008 - val_loss: 0.9857 - val_accuracy: 0.8258\n",
      "\n",
      "Epoch 00055: val_accuracy improved from 0.82398 to 0.82584, saving model to french_eng_finalmodel\n",
      "Epoch 56/100\n",
      "44800/44800 [==============================] - 243s 5ms/step - loss: 0.4383 - accuracy: 0.9052 - val_loss: 0.9749 - val_accuracy: 0.8276\n",
      "\n",
      "Epoch 00056: val_accuracy improved from 0.82584 to 0.82758, saving model to french_eng_finalmodel\n",
      "Epoch 57/100\n",
      "44800/44800 [==============================] - 243s 5ms/step - loss: 0.4151 - accuracy: 0.9097 - val_loss: 0.9674 - val_accuracy: 0.8298\n",
      "\n",
      "Epoch 00057: val_accuracy improved from 0.82758 to 0.82978, saving model to french_eng_finalmodel\n",
      "Epoch 58/100\n",
      "44800/44800 [==============================] - 232s 5ms/step - loss: 0.3951 - accuracy: 0.9145 - val_loss: 0.9601 - val_accuracy: 0.8324\n",
      "\n",
      "Epoch 00058: val_accuracy improved from 0.82978 to 0.83235, saving model to french_eng_finalmodel\n",
      "Epoch 59/100\n",
      "44800/44800 [==============================] - 236s 5ms/step - loss: 0.3766 - accuracy: 0.9181 - val_loss: 0.9516 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00059: val_accuracy improved from 0.83235 to 0.83332, saving model to french_eng_finalmodel\n",
      "Epoch 60/100\n",
      "44800/44800 [==============================] - 222s 5ms/step - loss: 0.3575 - accuracy: 0.9228 - val_loss: 0.9451 - val_accuracy: 0.8351\n",
      "\n",
      "Epoch 00060: val_accuracy improved from 0.83332 to 0.83508, saving model to french_eng_finalmodel\n",
      "Epoch 61/100\n",
      "44800/44800 [==============================] - 223s 5ms/step - loss: 0.3406 - accuracy: 0.9265 - val_loss: 0.9364 - val_accuracy: 0.8364\n",
      "\n",
      "Epoch 00061: val_accuracy improved from 0.83508 to 0.83639, saving model to french_eng_finalmodel\n",
      "Epoch 62/100\n",
      "44800/44800 [==============================] - 213s 5ms/step - loss: 0.3253 - accuracy: 0.9293 - val_loss: 0.9304 - val_accuracy: 0.8380\n",
      "\n",
      "Epoch 00062: val_accuracy improved from 0.83639 to 0.83803, saving model to french_eng_finalmodel\n",
      "Epoch 63/100\n",
      "44800/44800 [==============================] - 212s 5ms/step - loss: 0.3101 - accuracy: 0.9327 - val_loss: 0.9268 - val_accuracy: 0.8392\n",
      "\n",
      "Epoch 00063: val_accuracy improved from 0.83803 to 0.83923, saving model to french_eng_finalmodel\n",
      "Epoch 64/100\n",
      "44800/44800 [==============================] - 222s 5ms/step - loss: 0.2960 - accuracy: 0.9357 - val_loss: 0.9240 - val_accuracy: 0.8402\n",
      "\n",
      "Epoch 00064: val_accuracy improved from 0.83923 to 0.84016, saving model to french_eng_finalmodel\n",
      "Epoch 65/100\n",
      "44800/44800 [==============================] - 223s 5ms/step - loss: 0.2824 - accuracy: 0.9389 - val_loss: 0.9215 - val_accuracy: 0.8412\n",
      "\n",
      "Epoch 00065: val_accuracy improved from 0.84016 to 0.84118, saving model to french_eng_finalmodel\n",
      "Epoch 66/100\n",
      "44800/44800 [==============================] - 228s 5ms/step - loss: 0.2697 - accuracy: 0.9410 - val_loss: 0.9148 - val_accuracy: 0.8427\n",
      "\n",
      "Epoch 00066: val_accuracy improved from 0.84118 to 0.84272, saving model to french_eng_finalmodel\n",
      "Epoch 67/100\n",
      "44800/44800 [==============================] - 227s 5ms/step - loss: 0.2581 - accuracy: 0.9436 - val_loss: 0.9169 - val_accuracy: 0.8437\n",
      "\n",
      "Epoch 00067: val_accuracy improved from 0.84272 to 0.84369, saving model to french_eng_finalmodel\n",
      "Epoch 68/100\n",
      "44800/44800 [==============================] - 231s 5ms/step - loss: 0.2472 - accuracy: 0.9461 - val_loss: 0.9119 - val_accuracy: 0.8457\n",
      "\n",
      "Epoch 00068: val_accuracy improved from 0.84369 to 0.84573, saving model to french_eng_finalmodel\n",
      "Epoch 69/100\n",
      "44800/44800 [==============================] - 231s 5ms/step - loss: 0.2369 - accuracy: 0.9479 - val_loss: 0.9096 - val_accuracy: 0.8449\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.84573\n",
      "Epoch 70/100\n",
      "44800/44800 [==============================] - 218s 5ms/step - loss: 0.2273 - accuracy: 0.9499 - val_loss: 0.9043 - val_accuracy: 0.8464\n",
      "\n",
      "Epoch 00070: val_accuracy improved from 0.84573 to 0.84638, saving model to french_eng_finalmodel\n",
      "Epoch 71/100\n",
      "44800/44800 [==============================] - 209s 5ms/step - loss: 0.2179 - accuracy: 0.9518 - val_loss: 0.9073 - val_accuracy: 0.8466\n",
      "\n",
      "Epoch 00071: val_accuracy improved from 0.84638 to 0.84659, saving model to french_eng_finalmodel\n",
      "Epoch 72/100\n",
      "44800/44800 [==============================] - 214s 5ms/step - loss: 0.2096 - accuracy: 0.9535 - val_loss: 0.9052 - val_accuracy: 0.8466\n",
      "\n",
      "Epoch 00072: val_accuracy improved from 0.84659 to 0.84662, saving model to french_eng_finalmodel\n",
      "Epoch 73/100\n",
      "44800/44800 [==============================] - 216s 5ms/step - loss: 0.2014 - accuracy: 0.9551 - val_loss: 0.9030 - val_accuracy: 0.8484\n",
      "\n",
      "Epoch 00073: val_accuracy improved from 0.84662 to 0.84836, saving model to french_eng_finalmodel\n",
      "Epoch 74/100\n",
      "44800/44800 [==============================] - 217s 5ms/step - loss: 0.1934 - accuracy: 0.9565 - val_loss: 0.9032 - val_accuracy: 0.8493\n",
      "\n",
      "Epoch 00074: val_accuracy improved from 0.84836 to 0.84929, saving model to french_eng_finalmodel\n",
      "Epoch 75/100\n",
      "44800/44800 [==============================] - 217s 5ms/step - loss: 0.1852 - accuracy: 0.9582 - val_loss: 0.9049 - val_accuracy: 0.8482\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.84929\n",
      "Epoch 76/100\n",
      "44800/44800 [==============================] - 215s 5ms/step - loss: 0.1783 - accuracy: 0.9599 - val_loss: 0.9052 - val_accuracy: 0.8487\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.84929\n",
      "Epoch 77/100\n",
      "44800/44800 [==============================] - 213s 5ms/step - loss: 0.1723 - accuracy: 0.9610 - val_loss: 0.9019 - val_accuracy: 0.8499\n",
      "\n",
      "Epoch 00077: val_accuracy improved from 0.84929 to 0.84988, saving model to french_eng_finalmodel\n",
      "Epoch 78/100\n",
      "44800/44800 [==============================] - 213s 5ms/step - loss: 0.1658 - accuracy: 0.9623 - val_loss: 0.8992 - val_accuracy: 0.8503\n",
      "\n",
      "Epoch 00078: val_accuracy improved from 0.84988 to 0.85028, saving model to french_eng_finalmodel\n",
      "Epoch 79/100\n",
      "44800/44800 [==============================] - 217s 5ms/step - loss: 0.1590 - accuracy: 0.9636 - val_loss: 0.9069 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.85028\n",
      "Epoch 80/100\n",
      "44800/44800 [==============================] - 208s 5ms/step - loss: 0.1546 - accuracy: 0.9646 - val_loss: 0.9040 - val_accuracy: 0.8498\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.85028\n",
      "Epoch 81/100\n",
      "44800/44800 [==============================] - 209s 5ms/step - loss: 0.1481 - accuracy: 0.9659 - val_loss: 0.9072 - val_accuracy: 0.8501\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.85028\n",
      "Epoch 82/100\n",
      "44800/44800 [==============================] - 210s 5ms/step - loss: 0.1433 - accuracy: 0.9672 - val_loss: 0.9065 - val_accuracy: 0.8515\n",
      "\n",
      "Epoch 00082: val_accuracy improved from 0.85028 to 0.85151, saving model to french_eng_finalmodel\n",
      "Epoch 83/100\n",
      "44800/44800 [==============================] - 215s 5ms/step - loss: 0.1385 - accuracy: 0.9676 - val_loss: 0.9074 - val_accuracy: 0.8517\n",
      "\n",
      "Epoch 00083: val_accuracy improved from 0.85151 to 0.85166, saving model to french_eng_finalmodel\n",
      "Epoch 84/100\n",
      "44800/44800 [==============================] - 210s 5ms/step - loss: 0.1331 - accuracy: 0.9693 - val_loss: 0.9055 - val_accuracy: 0.8522\n",
      "\n",
      "Epoch 00084: val_accuracy improved from 0.85166 to 0.85217, saving model to french_eng_finalmodel\n",
      "Epoch 85/100\n",
      "44800/44800 [==============================] - 213s 5ms/step - loss: 0.1290 - accuracy: 0.9699 - val_loss: 0.9076 - val_accuracy: 0.8522\n",
      "\n",
      "Epoch 00085: val_accuracy improved from 0.85217 to 0.85219, saving model to french_eng_finalmodel\n",
      "Epoch 86/100\n",
      "44800/44800 [==============================] - 211s 5ms/step - loss: 0.1256 - accuracy: 0.9706 - val_loss: 0.9110 - val_accuracy: 0.8520\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.85219\n",
      "Epoch 87/100\n",
      "44800/44800 [==============================] - 209s 5ms/step - loss: 0.1215 - accuracy: 0.9716 - val_loss: 0.9115 - val_accuracy: 0.8523\n",
      "\n",
      "Epoch 00087: val_accuracy improved from 0.85219 to 0.85230, saving model to french_eng_finalmodel\n",
      "Epoch 88/100\n",
      "44800/44800 [==============================] - 225s 5ms/step - loss: 0.1170 - accuracy: 0.9727 - val_loss: 0.9124 - val_accuracy: 0.8521\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.85230\n",
      "Epoch 89/100\n",
      "44800/44800 [==============================] - 217s 5ms/step - loss: 0.1133 - accuracy: 0.9732 - val_loss: 0.9114 - val_accuracy: 0.8526\n",
      "\n",
      "Epoch 00089: val_accuracy improved from 0.85230 to 0.85265, saving model to french_eng_finalmodel\n",
      "Epoch 90/100\n",
      "44800/44800 [==============================] - 215s 5ms/step - loss: 0.1095 - accuracy: 0.9740 - val_loss: 0.9161 - val_accuracy: 0.8528\n",
      "\n",
      "Epoch 00090: val_accuracy improved from 0.85265 to 0.85279, saving model to french_eng_finalmodel\n",
      "Epoch 91/100\n",
      "44800/44800 [==============================] - 217s 5ms/step - loss: 0.1067 - accuracy: 0.9747 - val_loss: 0.9180 - val_accuracy: 0.8529\n",
      "\n",
      "Epoch 00091: val_accuracy improved from 0.85279 to 0.85294, saving model to french_eng_finalmodel\n",
      "Epoch 92/100\n",
      "44800/44800 [==============================] - 213s 5ms/step - loss: 0.1034 - accuracy: 0.9753 - val_loss: 0.9191 - val_accuracy: 0.8531\n",
      "\n",
      "Epoch 00092: val_accuracy improved from 0.85294 to 0.85311, saving model to french_eng_finalmodel\n",
      "Epoch 93/100\n",
      "44800/44800 [==============================] - 208s 5ms/step - loss: 0.1001 - accuracy: 0.9762 - val_loss: 0.9197 - val_accuracy: 0.8534\n",
      "\n",
      "Epoch 00093: val_accuracy improved from 0.85311 to 0.85340, saving model to french_eng_finalmodel\n",
      "Epoch 94/100\n",
      "44800/44800 [==============================] - 212s 5ms/step - loss: 0.0970 - accuracy: 0.9767 - val_loss: 0.9263 - val_accuracy: 0.8531\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.85340\n",
      "Epoch 95/100\n",
      "44800/44800 [==============================] - 209s 5ms/step - loss: 0.0939 - accuracy: 0.9775 - val_loss: 0.9241 - val_accuracy: 0.8536\n",
      "\n",
      "Epoch 00095: val_accuracy improved from 0.85340 to 0.85362, saving model to french_eng_finalmodel\n",
      "Epoch 96/100\n",
      "44800/44800 [==============================] - 215s 5ms/step - loss: 0.0906 - accuracy: 0.9783 - val_loss: 0.9282 - val_accuracy: 0.8529\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.85362\n",
      "Epoch 97/100\n",
      "44800/44800 [==============================] - 212s 5ms/step - loss: 0.0889 - accuracy: 0.9785 - val_loss: 0.9299 - val_accuracy: 0.8537\n",
      "\n",
      "Epoch 00097: val_accuracy improved from 0.85362 to 0.85369, saving model to french_eng_finalmodel\n",
      "Epoch 98/100\n",
      "44800/44800 [==============================] - 214s 5ms/step - loss: 0.0866 - accuracy: 0.9790 - val_loss: 0.9316 - val_accuracy: 0.8534\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.85369\n",
      "Epoch 99/100\n",
      "44800/44800 [==============================] - 210s 5ms/step - loss: 0.0834 - accuracy: 0.9798 - val_loss: 0.9344 - val_accuracy: 0.8534\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.85369\n",
      "Epoch 100/100\n",
      "44800/44800 [==============================] - 211s 5ms/step - loss: 0.0815 - accuracy: 0.9802 - val_loss: 0.9350 - val_accuracy: 0.8533\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.85369\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "z = np.zeros((encoder_inputs.shape[0], LATENT_DIM_DECODER)) # initial [s, c]\n",
    "r = model.fit(\n",
    "  [encoder_inputs, decoder_inputs, z, z], decoder_targets_one_hot,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  epochs=EPOCHS,\n",
    "  validation_split=0.2,\n",
    "    callbacks=callbacks_list\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot some data\n",
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# accuracies\n",
    "plt.plot(r.history['accuracy'], label='acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying the model for Predictions\n",
    "While training, we know the actual inputs to the decoder for all the output words in the sequence. However, during predictions the next word will be predicted on the basis of the previous word, which in turn is also predicted in the previous time-step. \n",
    "\n",
    "While making actual predictions, the full output sequence is not available, in fact that is what we have to predict. During prediction the only start and end token is avaialbale to us. We will use this to predict the output sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs_placeholder, encoder_outputs)\n",
    "\n",
    "# next we define a T=1 decoder model\n",
    "encoder_outputs_as_input = Input(shape=(max_len_input, LATENT_DIM * 2,))\n",
    "decoder_inputs_single = Input(shape=(1,))\n",
    "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n",
    "\n",
    "# no need to loop over attention steps this time because there is only one step\n",
    "context = one_step_attention(encoder_outputs_as_input, initial_s)\n",
    "\n",
    "# combine context with last word\n",
    "decoder_lstm_input = context_last_word_concat_layer([context, decoder_inputs_single_x])\n",
    "\n",
    "# lstm and final dense\n",
    "o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[initial_s, initial_c])\n",
    "decoder_outputs = decoder_dense(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "decoder_model = Model(\n",
    "  inputs=[\n",
    "    decoder_inputs_single,\n",
    "    encoder_outputs_as_input,\n",
    "    initial_s, \n",
    "    initial_c\n",
    "  ],\n",
    "  outputs=[decoder_outputs, s, c]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model.save(\"enfr_decoder_model.h5\")\n",
    "encoder_model.save(\"enfr_encoder_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions\n",
    "\n",
    "In the tokenization steps, we converted words to integers. The outputs from the decoder will also be integers. However, we want our output to be a sequence of words in the French language. To do so, we need to convert the integers back to words. We will create new dictionaries for both inputs and outputs where the keys will be the integers and the corresponding values will be the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word_eng = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_trans = {v:k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump( idx2word_eng, open( \"idx2word_eng1.pkl\", \"wb\" ) )\n",
    "pickle.dump(idx2word_trans,open(\"idx2word_fr.pkl\",\"wb\"))\n",
    "pickle.dump(tokenizer_inputs,open(\"tokenizer_inputs.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decode_sequence() method will accept an input-padded sequence french sentence (in the integer form) and will return the translated english sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "  # Encode the input as state vectors.\n",
    "  enc_out = encoder_model.predict(input_seq)\n",
    "\n",
    "  # Generate empty target sequence of length 1.\n",
    "  target_seq = np.zeros((1, 1))\n",
    "  \n",
    "  # Populate the first character of target sequence with the start character.\n",
    "  # NOTE: tokenizer lower-cases all words\n",
    "  target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "\n",
    "  # if we get this we break\n",
    "  eos = word2idx_outputs['<eos>']\n",
    "\n",
    "\n",
    "  # [s, c] will be updated in each loop iteration\n",
    "  s = np.zeros((1, LATENT_DIM_DECODER))\n",
    "  c = np.zeros((1, LATENT_DIM_DECODER))\n",
    "\n",
    "\n",
    "  # Create the translation\n",
    "  output_sentence = []\n",
    "  for _ in range(max_len_target):\n",
    "    o, s, c = decoder_model.predict([target_seq, enc_out, s, c])\n",
    "        \n",
    "\n",
    "    # Get next word\n",
    "    idx = np.argmax(o.flatten())\n",
    "\n",
    "    # End sentence of EOS\n",
    "    if eos == idx:\n",
    "      break\n",
    "\n",
    "    word = ''\n",
    "    if idx > 0:\n",
    "      word = idx2word_trans[idx]\n",
    "      output_sentence.append(word)\n",
    "\n",
    "    # Update the decoder input\n",
    "    # which is just the word just generated\n",
    "    target_seq[0, 0] = idx\n",
    "\n",
    "  return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model\n",
    "To test the model, we use the french sentences from the test set, retrieve the corresponding padded sequence for the sentence, and will pass it to the decode_sequence() method. The method will return the translated sentence as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_actual_sentence=[]\n",
    "test_predicted_sentence=[]\n",
    "for i in range(len(fr_test)):\n",
    "    # Do some test translations\n",
    "  \n",
    "  input_seq = encoder_inputs_test[i:i+1]\n",
    "  translation = decode_sequence(input_seq)\n",
    "\n",
    "  test_actual_sentence.append(target_texts_test[i])\n",
    "  test_predicted_sentence.append(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: soyez polis avec vos parents\n",
      "Predicted translation: be polite to your parents\n",
      "Actual translation: be polite to your parents <eos>\n",
      "-\n",
      "Input sentence: ma vie pour une bire\n",
      "Predicted translation: my life is like to beer\n",
      "Actual translation: im dying for a beer <eos>\n",
      "-\n",
      "Input sentence: je suis heureuse que vous veniez\n",
      "Predicted translation: im glad youre coming\n",
      "Actual translation: im glad youre coming <eos>\n",
      "-\n",
      "Input sentence: sa voiture a deux ans\n",
      "Predicted translation: his car is two years old\n",
      "Actual translation: his car is two years old <eos>\n",
      "-\n",
      "Input sentence: dsole je ne vous ai pas entendus\n",
      "Predicted translation: sorry i didnt hear you\n",
      "Actual translation: sorry i didnt hear you <eos>\n"
     ]
    }
   ],
   "source": [
    "for i in np.random.randint(0,14000,5):\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts_test[i])\n",
    "    print('Predicted translation:', test_predicted_sentence[i])\n",
    "    print('Actual translation:', target_texts_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metric: BLEU Score\n",
    "\n",
    "BLEU, or the Bilingual Evaluation Understudy, is a score for comparing a candidate translation of text to one or more reference translations. NLTK also provides a function called corpus_bleu() for calculating the BLEU score for multiple sentences such as a paragraph or a document.\n",
    "\n",
    "The references must be specified as a list of sentences where each sentence is a list of references and each alternative reference is a list of tokens, e.g. a list of lists of lists of tokens. The candidate sentences must be specified as a list where each sentence is a list of tokens\n",
    "\n",
    "Here we will be passing predicted translations as list of candidate sentences and actual sentences as list of reference sentences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "pred=[]\n",
    "for words in test_predicted_sentence:\n",
    "    pred.append(words.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual=[]\n",
    "for words in test_actual_sentence:\n",
    "    actual.append(words.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2860901377075264\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "chencherry = SmoothingFunction()\n",
    "BLEUscore = nltk.translate.bleu_score.corpus_bleu(actual,pred,smoothing_function=chencherry.method4)\n",
    "print(BLEUscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Could not import signal.SIGPIPE (this is expected on Windows machines)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 37.88 68.3/51.5/41.6/35.5 (BP = 0.794 ratio = 0.812 hyp_len = 59438 ref_len = 73164)\n"
     ]
    }
   ],
   "source": [
    "import sacrebleu\n",
    "x=sacrebleu.raw_corpus_bleu(test_predicted_sentence,[test_actual_sentence])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
